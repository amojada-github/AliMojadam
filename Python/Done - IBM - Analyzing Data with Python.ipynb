{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Reading data from python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas documentation http://pandas.pydata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# dataset doesn't have headers\n",
    "df = pd.read_csv('url', header = None)\n",
    "df = pd.read_json('url', header = None)\n",
    "df = pd.read_excel('url', header = None)\n",
    "df = pd.read_sql('url', header = None)\n",
    "# defining header name\n",
    "headers = ['sex', 'age',..., 'price']\n",
    "\n",
    "# assigning names to columns headers\n",
    "df.columns = headers\n",
    "\n",
    "# OR\n",
    "\n",
    "df = pd.read_csv('url', names = headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('path')\n",
    "df.to_csv('path')\n",
    "df.to_csv('path')\n",
    "df.to_csv('path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Starting with Data Analysis in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# panda data types:\n",
    "\n",
    "###  object (strings)\n",
    "###  int64  (numeric characters)\n",
    "###  float64 (numerica characters with decimals)\n",
    "###  datetime64,timedelta[ns] -- timeseries type\n",
    "\n",
    "##  python native data types:\n",
    "\n",
    "###  string\n",
    "###  int\n",
    "###  float\n",
    "###  N/A (i.e. no timeseries data type in native python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data type\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Statistical Summary\n",
    "\n",
    "df.describe()  # only numerical columns\n",
    "dff.describe(include = 'all') # ALL columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concise Summary of Data  - top and bottom 30 rows of the dataframe\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Changing the values in specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6f07c802b055>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'columnname'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'columnname'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['columnname'] = df['columnname'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling/replacing missing values in python\n",
    "\n",
    "### First: Evaluating for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "missing_data = df.isnull()\n",
    "\n",
    "Non-missing data = df.notnull()\n",
    "\n",
    "missing_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count missing values in each column!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in missing_data.columns.values.tolist():\n",
    "    print(column)\n",
    "    print(missing_data[column].value_counts()) # .value_counts(): counts the number of True's\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When dropping values from a column, INDEX should be reset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows in 'price'\n",
    "\n",
    "df.dropna(subset=['price'], axis = 0, inplace = True)\n",
    "\n",
    "# reset index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna() # axis = 0 to drop ROW, axis = 1 to drop COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = ['price'], axis = 0, inplace = True)\n",
    "\n",
    "# inplace = True : changes will happen in the datafram directly\n",
    "\n",
    "df.dropna(subset = ['price'], axis = 0) # DOES NOT change the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replacing Missing values with mean\n",
    "\n",
    "import numpy as np\n",
    "df.replace(missing_value, new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### replacing with mean of a column\n",
    "import numpy as np\n",
    "\n",
    "mean = df['columnname'].mean()\n",
    "df['columnname'].replace(np.nan, mean)\n",
    "\n",
    "# Example of replacing NaN with mean \n",
    "\n",
    "avg = df['columnname'].astype('float').mean(axis=0)\n",
    "df['columnname'].replace(np.nan, avg, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replacing values in the ENTIRE dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "df.replace('?', np.nan, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting the frequency of different values in a feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['columnname'].value_counts() # gives count of distinct values\n",
    "\n",
    "## Getting the most frequent value in a feature\n",
    "\n",
    "df['columnname'].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Formatting or Data standardization - bringining data into a common format\n",
    "\n",
    "#### Data Formatting makes data more understandable. Makes statistical analyses easier. e.g. writing NY, N.Y, New York instead of just 'New York' OR having to convert mpg (miles per gallon) to metric units (Liter per Km) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpg to l/km\n",
    "df['mpg'] = 235/df['mpg']\n",
    "\n",
    "#renaming columns\n",
    "\n",
    "df.rename(columns={'mpg': 'L/Km'}, inplace = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to correct data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking datatype\n",
    "\n",
    "df.dtypes()\n",
    "\n",
    "\n",
    "# converting data types\n",
    "\n",
    "df.astype()\n",
    "\n",
    "# e.g.\n",
    "\n",
    "df['price'] = df['price'].astype('int')\n",
    "\n",
    "df[['col1', 'col2',...]] = df[['col1', 'col2',...]].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization in Python (important to data pre-processing)\n",
    "\n",
    "\n",
    "#### data normalization makes the RANGE OF VALUES consistent. This makes statistical analysis easier down the road. it enables a fair comparison between features.\n",
    "\n",
    "# Why is Data Normalization important?\n",
    "\n",
    "##### Take the comparison of 'age' and 'income' columns in a dataset. 'Age' ranges from 0 -100 but 'income' might range from 20,000 to 500,000. If we're running Linear Regression, for example, the wider range of values for the 'income' column impacts the output of the model more heavily, even though it is not necessarily a more important variable than 'age'.\n",
    "\n",
    "# Ways to normalize value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Simple Feature Scaling\n",
    "\n",
    "Xnew = Xold / Xmax\n",
    "\n",
    "# e.g.\n",
    "\n",
    "df['length'] = df['length']/df['length'].max()\n",
    "\n",
    "# Method 2: Min-Max method\n",
    "\n",
    "Xnew = (Xold - Xmin)/(Xmax - Xmin)\n",
    "\n",
    "df['length'] = (df['length'] - df['length'].min) / (df['length'].max() - df['length'].min())\n",
    "\n",
    "# e.g.\n",
    "\n",
    "# Method 3: Z-Score\n",
    "\n",
    "Xnew = (Xold - avg(X)) / Std(X)\n",
    "\n",
    "# e.g.\n",
    "\n",
    "df['length'] = (df['length'] - df['length'].mean()) / df['length'].std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning - Values into groups\n",
    " #### Binning can help us better understand the distribution of values of a numerical feature.i.e. price would be bins = low, medium, high\n",
    " \n",
    "### Creating 3 bins based on the 'price' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# step 1: saving 4 equally spaced values within the specified range within the feature\n",
    "\n",
    "bins = np.linspace(min(df['price']), max(df['price']), 4)\n",
    "\n",
    "# step 2: bin names\n",
    "\n",
    "group_names = ['low', 'medium', 'high']\n",
    "\n",
    "# step 3 : creating the 'price-binned' column\n",
    "\n",
    "df['price-binned'] = pd.cut(df['price'], bins, labels = group_names, include_lowest = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Categorical into Numerical variables\n",
    "\n",
    "### We do this because most statistical models cannot take in object or strings as input\n",
    "\n",
    "## Method: One-hot encoding OR Creating dummy variables ( assigning 0 or 1 in each category)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating dummies\n",
    "\n",
    "dummy_fuel = pd.get_dummies(df['fuel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Dummy variables with dataset and dropping original column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, dummy_fuel], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "## Dropping original variable\n",
    "\n",
    "df.drop('fuel', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# histograph without specifying bins\n",
    "plt.pyplot.hist(df['colname'])\n",
    "\n",
    "# histogram with specifying bins\n",
    "plt.pyplot.hist(df['colname'], bins = 3)\n",
    "\n",
    "# Setting x & y labels\n",
    "\n",
    "plt.pyplot.xlabel('horsepower')\n",
    "plt.pyplot.ylabel('count')\n",
    "plt.pyplot.title('horsepower bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "pyplot.bar(category_names, df['colname'].value_counts())\n",
    "\n",
    "\n",
    "# Setting x & y labels\n",
    "\n",
    "plt.pyplot.xlabel('horsepower')\n",
    "plt.pyplot.ylabel('count')\n",
    "plt.pyplot.title('horsepower bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics\n",
    "#### Statistically summarizing data to get to know the data better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot\n",
    "\n",
    "#### Boxplots are great for visualizing the distribution of numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = \"colname\", y= \"colname\", data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot\n",
    "\n",
    "#### Scatterplot allows us to example the relationship between the predictor (x-axis) and the target (y-axis) variable.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"colname\"]\n",
    "x = df[\"colname\"]\n",
    "sns.scatter(x,y)\n",
    "\n",
    "\n",
    "# axis titles\n",
    "\n",
    "plt.title(\"plot title\")\n",
    "plt.xlabel(\"x-axis title\")\n",
    "plt.ylable(\"y-axis title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping Data in Python - .Groupby()\n",
    "\n",
    "#### 1. Groupby method is used on categorical variables.\n",
    "#### 2. .Groupby() groups data into subsets according to the categories of the variable\n",
    "#### 3. Groupby() can group by a single or multiple variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR EXAMPLE: Examning the average \"Price\" across different \"drive-wheels\" and \"body-style\" categories.\n",
    "\n",
    "# Step 1: Creating a dataset that consists of all columns we want to look at\n",
    "\n",
    "df_test = df[['drive-wheels', 'body-style', 'price']]\n",
    "\n",
    "# Step 2: Examining 'average price' for various categories in # wheels and different body-styles\n",
    "df_group = df_test.groupby(['drive-wheels', 'body-style'], as_index=False).mean()\n",
    "df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### How to pivot a table in Python: Exchanging rows and columns with one another\n",
    "\n",
    "df_pivot = df_group.pivot(index = 'variablename', columns = 'variablename')\n",
    "\n",
    "https://www.youtube.com/watch?v=q9ColmygT0s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmap\n",
    "\n",
    "#### Plots target variable over multiple variables (and various categories within these variables) in a visual way\n",
    "\n",
    "#### Heathmaps are most suitable for pivot tables in python!\n",
    "\n",
    "plt.pcolor(df_pivot, cmap = 'RdBu')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation\n",
    "\n",
    "## A statistical metric to measure to what extent two variables are INTERDEPENDENT. In other words, how does change in one impact the other.\n",
    "\n",
    "### Example: Correlation between 'engine size' AND  'price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### scatter plot with regression line\n",
    "\n",
    "sns.regplot(x='engine-size', y='price', data=df)\n",
    "plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pearson Correlation\n",
    "\n",
    "### A method to examine the correlation between continuous variables.\n",
    "####Pearson correlation gives us: Correlation Coefficients AND p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation\n",
    "\n",
    "# Step 1: \n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Step 2:\n",
    "\n",
    "pearson_coef, p_value = stats.pearsonr(df['predictor_variable'], df['target_variable'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA - Analysis of Variance\n",
    "\n",
    "### Used for analyzing Categorical Variables. ANOVA can be used to find correlation between different groups of a categorical variable. \n",
    "\n",
    "#### For example, we can use ANOVA to see if there is any difference in the impact of different car makes on 'Price'. \n",
    "\n",
    "### ANOVA returns two values: \n",
    "#### F-test score: The variation between \"means of categories\" and divided by variation of each category.\n",
    "#### p-value: statistical significane degree\n",
    "\n",
    "#### Large F-test score and Small p-value MEANS : There is a strong correlation between a Categorical variable and a target variable.\n",
    "\n",
    "https://www.youtube.com/watch?v=wMQ5oVuXK7o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA using the scipy mpackage\n",
    "\n",
    "# For exmple: relationship between the variaous 'car make' categories and 'price'\n",
    "\n",
    "import scipy as stats\n",
    "\n",
    "df_anova = df[[\"make\", \"price\"]]\n",
    "grouped_anova = df_anova.groupby([\"make\"])\n",
    "\n",
    "\n",
    "anova_results_1 = stats.f_oneway(grouped_anova.get_group(\"honda\")[\"price\"],grouped_anova.get_group(\"subaru\")[\"price\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Simple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ea1510e283ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Step 3: We define the predictor variable and the target variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'highway-mpg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 1:\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Step 2: Create a Linear Regression Object using the constructor\n",
    "\n",
    "lm = LinearRegression()\n",
    "\n",
    "\n",
    "# Step 3: We define the predictor variable and the target variable\n",
    "\n",
    "X = df[['highway-mpg']]\n",
    "Y = df['price']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
